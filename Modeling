# Imports
import matplotlib
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import sys
import math
import datetime
import numpy
import statistics
from matplotlib.pyplot import figure
import plotly.express as px
import plotly.io as pio
from statsmodels.tsa.stattools import grangercausalitytests
from statsmodels.tsa.statespace.sarimax import SARIMAX
from sklearn.model_selection import TimeSeriesSplit
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from prophet import Prophet
from neuralprophet import NeuralProphet
import statsmodels as sm
import plotly.graph_objects as go
from sklearn.metrics import mean_squared_error
import warnings
warnings.filterwarnings("ignore")

# Change Directory
os.chdir(r'C:\Users\tauruskevicius\projects\ia_fcst_capacity\data')

# Read in data
capacity = pd.read_csv('./Demonstrated Capacity.csv')
inventory = pd.read_csv('./Inventory.csv')
sales = pd.read_csv('./Cases Sold.csv')
mapping = pd.read_csv('./Market Mapping.csv')

# # Cleanup Dataframes

# # Cleanup Dataframes

dates = inventory.groupby('FISCAL_YEAR_WEEK')['DATE'].min().reset_index()
dates['FISCAL_YEAR_WEEK'] = dates['FISCAL_YEAR_WEEK'].astype('int')

# Capacity
capacity = capacity.rename(columns={'BRNCH_CD':'BRANCH_CODE', 'DATE_EXTRACT':'DATE'})
capacity = capacity.groupby(['BRANCH_CODE', 'DATE']).agg({'DEMONSTRATED_CASES':'sum'}).reset_index()
capacity = capacity.merge(inventory[['BRANCH_CODE', 'DATE', 'FISCAL_YEAR_WEEK']],
                          on = ['BRANCH_CODE', 'DATE'],
                          how = 'left') # Bring fiscal week
capacity['FISCAL_YEAR_WEEK'] = capacity['FISCAL_YEAR_WEEK'].ffill() # Fill some NaN
capacity = capacity.groupby(['BRANCH_CODE', 'FISCAL_YEAR_WEEK']).agg({'DEMONSTRATED_CASES':'max'}).reset_index()
#capacity['FISCAL_YEAR_WEEK'] = capacity['FISCAL_YEAR_WEEK'].astype(int).astype(str)
capacity = capacity.merge(dates, how = 'left', on='FISCAL_YEAR_WEEK')
capacity_max = capacity.groupby(['BRANCH_CODE'])['DEMONSTRATED_CASES'].max().reset_index()

# Inventory
inventory = inventory.loc[inventory.DATE != '2021-11-25']
inventory = inventory.groupby(['MARKET', 'BRANCH_CODE', 'FISCAL_YEAR_WEEK']).agg({'CASES_INVENTORY':'max'}).reset_index()
#inventory = inventory.merge(dates, how = 'left', on='FISCAL_YEAR_WEEK')
inventory['FISCAL_YEAR_WEEK'] = inventory['FISCAL_YEAR_WEEK'].astype(str)

# Sales
sales = sales.merge(mapping[['DIV_NBR', 'BRNCH_CD']], on = 'DIV_NBR', how = 'left')
sales = sales.rename(columns = {'FISC_YR_WK':'FISCAL_YEAR_WEEK', 'BRNCH_CD':'BRANCH_CODE'})
sales['FISCAL_YEAR_WEEK'] = sales['FISCAL_YEAR_WEEK'].astype(str)
sales = sales.groupby(['BRANCH_CODE', 'FISCAL_YEAR_WEEK']).agg({'CASES_SOLD':'first'}).reset_index()
sales = sales.loc[sales.BRANCH_CODE.isin(inventory['BRANCH_CODE'].unique())]

# Join tables
df = inventory.merge(capacity_max, on = ['BRANCH_CODE'], how = 'left')
df = df.merge(sales, on = ['BRANCH_CODE', 'FISCAL_YEAR_WEEK'], how = 'inner').drop('MARKET', axis = 1)
df = df.loc[df['FISCAL_YEAR_WEEK'] != '202053']
df['FISCAL_YEAR_WEEK'] = df['FISCAL_YEAR_WEEK'].astype(int)
# Bring date back in
df = df.merge(dates, how = 'left', on = 'FISCAL_YEAR_WEEK')

# Add Sales LAGs
df['SALES_LAG5'] = df['CASES_SOLD'].shift(5)
# Remove the NaN that the shift causes
df = df.loc[df['SALES_LAG5'].notna()]

# Set Index to Date
df.loc[:,'DATE'] = pd.to_datetime(df['DATE'])
df.set_index(df.DATE, inplace=True)

# Replace Cases inventory 2020 data with 2019 data
df1 = df.copy()

# Replace 2020 data
for warehouse in df.BRANCH_CODE.unique():
    df.loc[(df.BRANCH_CODE == warehouse) & (df.FISCAL_YEAR_WEEK >= 202001) & (df.FISCAL_YEAR_WEEK <= 202052), 'CASES_INVENTORY'] = df.loc[(df.BRANCH_CODE == warehouse) & (df.FISCAL_YEAR_WEEK >= 201901) & (df.FISCAL_YEAR_WEEK <= 201952)]['CASES_INVENTORY'].values

df2 = df.copy()


# Define the function to return the MAPE values
def calculate_mape(actual, predicted) -> float:
    # Convert actual and predicted
    # to numpy array data type if not already
    if not all([isinstance(actual, np.ndarray),
                isinstance(predicted, np.ndarray)]):
        actual, predicted = np.array(actual),
        np.array(predicted)

    # Calculate the MAPE value and return
    return round(np.mean(np.abs((
                                    actual - predicted) / actual)) * 100, 2)

# SARIMA(X)
def SARIMAX(data, p, d, q, P=0, D=0, Q=0, endog=None, exog=None, i=None):
    model = sm.tsa.statespace.sarimax.SARIMAX(endog=endog,
                                              exog=exog,
                                              order=(p, d, q),
                                              seasonal_order=(P, D, Q, 52)).fit()

    if exog is None:
        pred = model.forecast(steps=5)
    else:
        pred = model.forecast(steps=5, exog=data.iloc[i:i + 5]["SALES_LAG5"])

    return pred.values


# Triple Exp Smoothing
def exp_smooth(endog, damped=True):
    model = ExponentialSmoothing(endog=endog,
                                 trend='add', seasonal='add',
                                 # use_boxcox=True,
                                 seasonal_periods=52).fit()
    pred = model.forecast(steps=5)

    return pred.values


# Facebook Prophet
def fbprophet(endog, i):
    prophet = Prophet().fit(endog[:i].to_frame().reset_index().rename(columns={'DATE': 'ds', 'CASES_INVENTORY': 'y'}))
    future = prophet.predict(temp['CASES_INVENTORY'][i:i + 5].to_frame().reset_index().rename(
        columns={'DATE': 'ds', 'CASES_INVENTORY': 'y'}))
    pred = prophet.predict(future)['yhat']

    return pred.values


# Nerual Prophet
def nprophet(endog, i):
    nprophet = NeuralProphet(learning_rate=0.05, seasonality_mode='multiplicative')

    metrics = nprophet.fit(endog[:i].to_frame().reset_index().rename(columns={'DATE': 'ds', 'CASES_INVENTORY': 'y'}),
                           freq='W')
    future = nprophet.make_future_dataframe(
        endog[:i].to_frame().reset_index().rename(columns={'DATE': 'ds', 'CASES_INVENTORY': 'y'}),
        periods=5)
    forecast = nprophet.predict(future)

    pred = forecast['yhat1']

    return pred.values


def evaluate_model(model, data, warehouse, endog, exog=None, p=0, d=0, q=0, P=0, D=0, Q=0):
    if model in ['naive']:

        for i in (range(-56, -1, 5)):
            train = endog.iloc[:i]
            test = endog.iloc[i:i + 5]

            # Prediction will just be avg
            pred = statistics.mean(train)
            preds = [pred, pred, pred, pred, pred]

            rmse = np.sqrt(mean_squared_error(y_true=test, y_pred=preds))
            mape = calculate_mape(np.array(test), np.array(preds))

            date1 = data.iloc[i].DATE.date()
            date2 = data.iloc[i + 4].DATE.date()

            # Add metrics to dictionary
            holdout_diagnostics[f'{date1} - {date2}'] = {'naive': rmse}
            holdout_diagnostics2[f'{date1} - {date2}'] = {'naive': mape}
            predictions[f'{date1} - {date2}'] = {'naive': preds}

    elif model in ['sarima', 'sarimax']:
        # sarima
        if exog is None:
            for i in (range(-56, -1, 5)):
                pred = SARIMAX(data, p, d, q, P, D, Q, endog.iloc[:i], None)

                rmse = np.sqrt(mean_squared_error(y_true=data.iloc[i:i + 5]['CASES_INVENTORY'], y_pred=pred))
                mape = calculate_mape(np.array(data.iloc[i:i + 5]['CASES_INVENTORY']), np.array(pred))

                date1 = data.iloc[i].DATE.date()
                date2 = data.iloc[i + 4].DATE.date()

                holdout_diagnostics[f'{date1} - {date2}']['sarima'] = rmse
                holdout_diagnostics2[f'{date1} - {date2}']['sarima'] = mape
                predictions[f'{date1} - {date2}']['sarima'] = pred


        # sarimax
        else:
            for i in (range(-56, -1, 5)):
                pred = SARIMAX(data, p, d, q, P, D, Q, endog.iloc[:i], exog.iloc[:i], i)

                rmse = np.sqrt(mean_squared_error(y_true=data.iloc[i:i + 5]['CASES_INVENTORY'], y_pred=pred))
                mape = calculate_mape(np.array(data.iloc[i:i + 5]['CASES_INVENTORY']), np.array(pred))

                date1 = data.iloc[i].DATE.date()
                date2 = data.iloc[i + 4].DATE.date()

                holdout_diagnostics[f'{date1} - {date2}']['sarimax'] = rmse
                holdout_diagnostics2[f'{date1} - {date2}']['sarimax'] = mape
                predictions[f'{date1} - {date2}']['sarimax'] = pred

    elif model in ['exp_smooth']:
        for i in (range(-56, -1, 5)):
            pred = exp_smooth(endog.iloc[:i])

            rmse = np.sqrt(mean_squared_error(y_true=data.iloc[i:i + 5]['CASES_INVENTORY'], y_pred=pred))
            mape = calculate_mape(np.array(data.iloc[i:i + 5]['CASES_INVENTORY']), np.array(pred))

            date1 = data.iloc[i].DATE.date()
            date2 = data.iloc[i + 4].DATE.date()

            holdout_diagnostics[f'{date1} - {date2}']['exponential_smoothing'] = rmse
            holdout_diagnostics2[f'{date1} - {date2}']['exponential_smoothing'] = mape
            predictions[f'{date1} - {date2}']['exponential_smoothing'] = pred

    elif model in ['prophet']:
        for i in (range(-56, -1, 5)):
            pred = fbprophet(endog, i)

            rmse = np.sqrt(mean_squared_error(y_true=data.iloc[i:i + 5]['CASES_INVENTORY'], y_pred=pred))
            mape = calculate_mape(np.array(data.iloc[i:i + 5]['CASES_INVENTORY']), np.array(pred))

            date1 = data.iloc[i].DATE.date()
            date2 = data.iloc[i + 4].DATE.date()

            holdout_diagnostics[f'{date1} - {date2}']['prophet'] = rmse
            holdout_diagnostics2[f'{date1} - {date2}']['prophet'] = mape
            predictions[f'{date1} - {date2}']['prophet'] = pred

    elif model in ['nprophet']:
        for i in (range(-56, -1, 5)):
            pred = nprophet(endog, i)

            rmse = np.sqrt(mean_squared_error(y_true=data.iloc[i:i + 5]['CASES_INVENTORY'], y_pred=pred))
            mape = calculate_mape(np.array(data.iloc[i:i + 5]['CASES_INVENTORY']), np.array(pred))

            date1 = data.iloc[i].DATE.date()
            date2 = data.iloc[i + 4].DATE.date()

            holdout_diagnostics[f'{date1} - {date2}']['nprophet'] = rmse
            holdout_diagnostics2[f'{date1} - {date2}']['nprophet'] = mape
            predictions[f'{date1} - {date2}']['nprophet'] = pred


def plot_rmse(holdout_diagnostics, rmse_df):
    time = list(holdout_diagnostics.keys())

    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=time,
        y=rmse_df['naive'],
        name='Naive Model',
        marker_color='darkturquoise'
    ))
    fig.add_trace(go.Bar(
        x=time,
        y=rmse_df['sarima'],
        name='SARIMA',
        marker_color='goldenrod'
    ))
    fig.add_trace(go.Bar(
        x=time,
        y=rmse_df['sarimax'],
        name='SARIMAX',
        marker_color='cornflowerblue'
    ))
    fig.add_trace(go.Bar(
        x=time,
        y=rmse_df['exponential_smoothing'],
        name='Exponential Smoothing',
        marker_color='tomato'
    ))

    fig.add_trace(go.Bar(
        x=time,
        y=rmse_df['prophet'],
        name='Facebook Prophet',
        marker_color='green'
    ))

    fig.add_trace(go.Bar(
        x=time,
        y=rmse_df['nprophet'],
        name='Neural Prophet',
        marker_color='purple'
    ))

    # Here we modify the tickangle of the xaxis, resulting in rotated labels.
    fig.update_layout(title=f'Model diagnostics for {warehouse} Warehouse', barmode='group', xaxis_tickangle=-45)
    fig.show()


def plot_predictions(predictions, data):
    # get first predicted date
    firstdate = pd.to_datetime(list(predictions.keys())[0].split(' ')[0])

    preds_df = data.CASES_INVENTORY.to_frame('True Inventory')[:-1]  # do not last two predicted values
    preds = pd.DataFrame.from_dict(predictions).transpose()
    models = list(preds.keys())
    preds_df[models] = np.nan

    # Unpack predicted values for each algorithm
    for i in range(0, len(preds.columns)):
        preds_df.loc[firstdate:, models[i]] = [item for sublist in preds.iloc[:, i].values for item in sublist]

    time = list(preds_df.index)

    fig = go.Figure()

    fig.add_trace(go.Scatter(
        x=time,
        y=preds_df['True Inventory'],
        name='True Inventory',
        marker_color='black'
    ))

    fig.add_trace(go.Scatter(
        x=time,
        y=preds_df['naive'],
        name='Naive Model',
        marker_color='darkturquoise'
    ))
    fig.add_trace(go.Scatter(
        x=time,
        y=preds_df['sarima'],
        name='SARIMA',
        marker_color='goldenrod'
    ))
    fig.add_trace(go.Scatter(
        x=time,
        y=preds_df['sarimax'],
        name='SARIMAX',
        marker_color='cornflowerblue'
    ))
    fig.add_trace(go.Scatter(
        x=time,
        y=preds_df['exponential_smoothing'],
        name='Exponential Smoothing',
        marker_color='tomato'
    ))

    fig.add_trace(go.Scatter(
        x=time,
        y=preds_df['prophet'],
        name='Facebook Prophet',
        marker_color='green'
    ))

    fig.add_trace(go.Scatter(
        x=time,
        y=preds_df['nprophet'],
        name='Neural Prophet',
        marker_color='purple'
    ))

    # Here we modify the tickangle of the xaxis, resulting in rotated labels.
    fig.update_layout(title=f'Model diagnostics for {warehouse} Warehouse', barmode='group', xaxis_tickangle=-45)
    fig.show()


# Fit a Model and Plot for each warehouse (messy code but get's the job done)
# Encode dataframe names
data = {0: 'Original', 1: '2019->2020'}
best_model2 = {} # Store best model for each warehouse for different datasets
mape = {} # Store MAPE for each warehouse for all CV dates

for i, df in enumerate([df1, df2]):
    best_model = {}

    # Fit a Model and Plot for each warehouse
    for warehouse in df.BRANCH_CODE.unique():

        # Get warehouse data
        temp = df.loc[df.BRANCH_CODE == warehouse]

        # Initiliaze Dicts
        holdout_diagnostics = {}
        holdout_diagnostics2 = {}
        predictions = {}

        #naive
        evaluate_model(model='naive', data=temp, warehouse=warehouse, endog=temp.CASES_INVENTORY)

        #SARIMA
        evaluate_model(model='sarima', data=temp, warehouse=warehouse, endog=temp.CASES_INVENTORY, exog=None, p=2,d=2,q=0,P=2,D=0,Q=0)

        #SARIMAX
        evaluate_model(model='sarimax', data=temp, warehouse=warehouse, endog=temp.CASES_INVENTORY, exog=temp.SALES_LAG5, p=2,d=2,q=0,P=2,D=0,Q=0)

        # Exponential Smoothing
        evaluate_model(model='exp_smooth', data=temp, warehouse=warehouse, endog=temp.CASES_INVENTORY)

        #Facebook Prophet
        evaluate_model(model='prophet', data=temp, warehouse=warehouse, endog=temp.CASES_INVENTORY)

        # Neural Prophet
        evaluate_model(model='nprophet', data=temp, warehouse=warehouse, endog=temp.CASES_INVENTORY)

        # Plot rmse
        rmse_df = pd.DataFrame.from_dict(holdout_diagnostics).transpose()
        plot_rmse(holdout_diagnostics, rmse_df)

        # Time series plot
        plot_predictions(predictions=predictions, data=temp)

        # Choose Best Model
        best_model[warehouse] = {'model':rmse_df.mean(axis=0).idxmin(), 'avgRMSE':rmse_df.mean(axis=0).min()}

        mape[warehouse] = holdout_diagnostics2

    # Store best models for each dataset & warehouse; best -> lowest average RMSE
    best_model2[data[i]] = best_model

# Plot FVA
for warehouse, mapes in mape.items():
    # Get Champion model
    champion = best_model2[data[1]][warehouse]['model']

    mape_df = pd.DataFrame.from_dict(mapes).transpose()
    mape_df['FVA'] = mape_df['naive'] - mape_df[champion]

    time = list(mape_df.index)

    fig = go.Figure()

    fig.add_trace(go.Scatter(
        x=time,
        y=mape_df.FVA,
        name='FVA',
        marker_color='black',
        fill='tozeroy',
        line_color='blue'
    ))
    fig.add_hline(y=0, line_width=3, line_dash="dash", line_color="red")

    # Here we modify the tickangle of the xaxis, resulting in rotated labels.
    fig.update_layout(title=f'FVA for {warehouse} Warehouse', xaxis_tickangle=-45)
    fig.show()

# Train models on full data and forecast into future

for warehouse in df.BRANCH_CODE.unique():
    temp = df.loc[df.BRANCH_CODE == warehouse].CASES_INVENTORY
    model = ExponentialSmoothing(endog=temp,
                                 trend='add', seasonal='add',
                                 # use_boxcox=True,
                                 seasonal_periods=52).fit()
    dates = pd.date_range(start=str(temp.index[-1].date() + datetime.timedelta(days=7)), periods=15, freq='7D').values
    pred = model.forecast(steps=15)

    preds = pd.Series(data=pred.values, index=pd.to_datetime(dates))

    time = pd.to_datetime(np.append(temp.index, preds.index))

    fig = go.Figure()

    fig.add_trace(go.Scatter(
        x=temp.index,
        y=temp,
        name='True Inventory',
        marker_color='black'
    ))

    fig.add_trace(go.Scatter(
        x=preds.index,
        y=preds,
        name='Forecast',
        marker_color='darkturquoise'
    ))

    # Here we modify the tickangle of the xaxis, resulting in rotated labels.
    fig.update_layout(title='Forecast for {} Warehouse'.format(warehouse), xaxis_tickangle=-45)
    fig.show()
